{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8f9bc3-1a80-478f-b7e3-a81207ce187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115e1b98-70a6-492d-a87e-25c9227614c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_variable_name = 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2fd8ab-4b0e-4b2a-9341-e7e1d578b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The environment variable 'OPENAI_API_KEY' is set \n"
     ]
    }
   ],
   "source": [
    "# Check if the environment variable is set\n",
    "if os.environ.get(environment_variable_name) is not None:\n",
    "  # The environment variable is set\n",
    "  print(f\"The environment variable '{environment_variable_name}' is set \")\n",
    "else:\n",
    "  # The environment variable is not set\n",
    "  print(f\"The environment variable '{environment_variable_name}' is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d54501e-41e5-4dd6-a7d8-3540e510240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b024c-e7f5-444e-8162-1e912dcb4777",
   "metadata": {},
   "source": [
    "# 4. Chat Completion method and Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9d1a8-56ae-463c-84bd-b1e9ff163e96",
   "metadata": {},
   "source": [
    "**openai.Completion.create()**: This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26116c3-04cc-44e2-8bc9-6d044600e80d",
   "metadata": {},
   "source": [
    "openai.ChatCompletion.create() : Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43151253-b7f4-4d00-8599-0699efed44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db58856-95a5-4ff5-8395-466a30b0b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"who won the first cricket worldcup?\"\n",
    "    }\n",
    "      ]\n",
    "    ,\n",
    "    max_tokens=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5eb05a7-ffdb-40f8-9b84-aa3ff5c6008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42dafa1d-e742-4e45-b953-a12449574f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KSsLyUKOvysv9CYQiZyTsrsxzxX9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final to emerge as the inaugural champions.', role='assistant', function_call=None, tool_calls=None))], created=1714664585, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=29, prompt_tokens=15, total_tokens=44))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49dd3e5-9723-46c7-9e6d-6c7ae794dae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final to emerge as the inaugural champions.', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acc0e10-8f52-47dc-9816-8f7675d25538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final to emerge as the inaugural champions.', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575b5760-156a-49c5-b931-b018cbc3dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final to emerge as the inaugural champions.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e0be9b-cc95-4ee5-902d-0af3c018e4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final to emerge as the inaugural champions.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b0f9e5-4ceb-42df-8fe6-7b01060c360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b03c956c-b605-4a92-b3a2-79afe403caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"Rahul Aggarwal is a student of computer science at DIT Delhi. His nationality is indian and has a 4.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in machine learning after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7049591d-5dfe-44ab-8e43-5e0acfe1daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rahul aggarwal is a student of computer science at DIT Delhi. He is an indian and has a 4.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in machine learning after graduating.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81ae9a2-ccaa-4567-b10c-20c55f8b90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc8ec86f-2483-4567-88b7-150592ae4385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nrahul aggarwal is a student of computer science at DIT Delhi. He is an indian and has a 4.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in machine learning after graduating.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac75a95d-1982-451a-bba5-470908059df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x2e063a7c280>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a33d14c4-ba26-4e31-8b95-4e8ffcf171c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b004a9-ba8d-49ba-97b5-18fdc24b0977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KTpx4SCjuTMpmna62qyEkyFWWVYc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Rahul Aggarwal\",\\n  \"college\": \"DIT Delhi\",\\n  \"grades\": \"4.5 GPA\",\\n  \"club\": \"AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1714668281, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_a450710239', usage=CompletionUsage(completion_tokens=41, prompt_tokens=105, total_tokens=146))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dad235ed-bcef-4b52-b7c7-da7cb939744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e634866-77f3-4269-adc2-8b0be67299d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Rahul Aggarwal\",\\n  \"college\": \"DIT Delhi\",\\n  \"grades\": \"4.5 GPA\",\\n  \"club\": \"AI Club\"\\n}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6cfedda-d8e7-4bcf-a24e-86a1a52ce773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Rahul Aggarwal',\n",
       " 'college': 'DIT Delhi',\n",
       " 'grades': '4.5 GPA',\n",
       " 'club': 'AI Club'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6b32c7f-3b21-4ac3-8eb0-202569faa5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                },\n",
    "                \n",
    "            },\n",
    "             \"required\": [\"name\", \"college\",\"grades\",\"club\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "625d0f55-789d-4f69-abe2-5287ea92de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt }],\n",
    "    functions = student_custom_function,\n",
    "    function_call=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8751ef5-02f8-4e0b-aabe-0eae2da7a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KUV9nJTJQ0uavANSrViF3eRZfsmx', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Rahul Aggarwal\",\"college\":\"DIT Delhi\",\"grades\":4.5,\"club\":\"AI Club\"}', name='extract_student_info'), tool_calls=None))], created=1714670835, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=37, prompt_tokens=190, total_tokens=227))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "554704d4-f3d0-4a81-80fd-730e442b61b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Rahul Aggarwal\",\"college\":\"DIT Delhi\",\"grades\":4.5,\"club\":\"AI Club\"}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdb4ce71-5189-4866-99ee-7c8a00ad2834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{\"name\":\"Rahul Aggarwal\",\"college\":\"DIT Delhi\",\"grades\":4.5,\"club\":\"AI Club\"}', name='extract_student_info')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32288437-c294-49e7-979f-70e53b5ef9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"Rahul Aggarwal\",\"college\":\"DIT Delhi\",\"grades\":4.5,\"club\":\"AI Club\"}'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7d173cf-83eb-422d-8bcc-b0d70947bb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "06062ccd-e4e7-4230-98b8-32773cb2bd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Rahul Aggarwal',\n",
       " 'college': 'DIT Delhi',\n",
       " 'grades': 4.5,\n",
       " 'club': 'AI Club'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4869dd76-67bc-4eea-aecd-8bdd54e027dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(response2.choices[0].message.function_call.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "408efbc7-c768-4699-9afb-96873e93a712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rahul aggarwal is a student of computer science at DIT Delhi. He is an indian and has a 4.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in machine learning after graduating.\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e6ba8e0-730f-44d9-a1cb-90688d04e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_two=\"Mark Zuck is a student of Arts at DAV Delhi. He is an indian and has a 1.5 GPA. Mark is known for his singing and is an active member of the college's singing Club. He hopes to pursue a career in Bollywood after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9014ef9-c9ed-4743-a232-d0b5fb38b2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mark Zuck is a student of Arts at DAV Delhi. He is an indian and has a 1.5 GPA. Mark is known for his singing and is an active member of the college's singing Club. He hopes to pursue a career in Bollywood after graduating.\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1d25ead-e504-4366-88e3-fea4932fc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_three=\"sudhanshu kumar is a student of computer science at IIT bengalore. He is an indian and has a 9.2 GPA. krish is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "099966e5-0ccf-49fb-a5d2-0d9ac31436b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sudhanshu kumar is a student of computer science at IIT bengalore. He is an indian and has a 9.2 GPA. krish is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b80cc0f3-2406-4f78-8ac5-7b771a7c4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rahul aggarwal is a student of computer science at DIT Delhi. He is an indian and has a 4.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in machine learning after graduating.\n",
      "Mark Zuck is a student of Arts at DAV Delhi. He is an indian and has a 1.5 GPA. Mark is known for his singing and is an active member of the college's singing Club. He hopes to pursue a career in Bollywood after graduating.\n",
      "sudhanshu kumar is a student of computer science at IIT bengalore. He is an indian and has a 9.2 GPA. krish is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\n"
     ]
    }
   ],
   "source": [
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e14536a1-2dec-45c6-8079-78b93816d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Rahul Aggarwal', 'college': 'DIT Delhi', 'grades': 4.5, 'club': 'AI Club'}\n",
      "{'name': 'Mark Zuck', 'college': 'DAV Delhi', 'grades': 1.5, 'club': 'singing'}\n",
      "{'name': 'Sudhanshu Kumar', 'college': 'IIT Bangalore', 'grades': 9.2, 'club': 'MLops Club'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = student_custom_function,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d9e73-80c4-47f3-8746-6ef41b0a0c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b730dc7a-a852-4e60-a025-d2c9810afcef",
   "metadata": {},
   "source": [
    "Calling two functions at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "506bc52f-9778-43d6-9ac4-238863337e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a second function to get information from the text\n",
    "function_two = [\n",
    "    {\n",
    "        'name': 'extract_student_residence',\n",
    "        'description': 'Get the student naitonality and place of residence',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'nationality': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Nationality of the person'\n",
    "                },\n",
    "                'hometown': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The hometown of the person.'\n",
    "                },\n",
    "                \n",
    "            },\n",
    "             \"required\": [\"nationality\", \"hometown\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dbdad0d9-8410-4c2b-b8fd-91126fceb9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Rahul Aggarwal', 'college': 'DIT Delhi', 'grades': 4.5, 'club': 'AI Club'}\n",
      "{'name': 'Mark Zuck', 'college': 'DAV Delhi', 'grades': 1.5, 'club': 'singing Club'}\n",
      "{'name': 'Sudhanshu Kumar', 'college': 'IIT Bangalore', 'grades': 9.2, 'club': 'MLops Club'}\n"
     ]
    }
   ],
   "source": [
    "#first function is used here since it matchesd the prompt\n",
    "functions = [student_custom_function[0], function_two[0]]\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "    \n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ee4325c7-43af-453b-9622-d005ec4a61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_three=\"sudhanshu kumar is of South Korean nationality and his hometown is Incheon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a578a329-1148-43a0-b310-b48267bfc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [student_custom_function[0], function_two[0]]\n",
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": student_description_three }],\n",
    "    functions = functions,\n",
    "    function_call=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "99d223f7-8c25-488b-a3f5-62758d8af57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"nationality\":\"South Korean\",\"residence\":\"Incheon\"}', name='extract_student_residence'), tool_calls=None))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e26d8d58-1a54-45d4-b276-65aafcf515b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence we can see that depending on the parameters match the correct function is called. below example proves it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf24de6-498a-48ee-8902-b30cd2546961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7845c1-e069-4af5-971d-47f815684eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4bcd5737-9bd7-4cbe-9fe0-ae97b6935ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced example of function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1dcd060c-5b20-4388-94f5-159688876499",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"When's the next flight from delhi to mumbai?\"\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b3c73c34-5523-4278-a348-e03018cf8201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am unable to provide real-time flight information. It is recommended to check with the airline or a flight tracking website for the most up-to-date information on flights from Delhi to Mumbai.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba4ea006-8179-4d06-b57a-147c3e7a82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. SFO\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. ZRH\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dfc49d42-a6de-4c62-96f9-3492e6d78e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When's the next flight from new delhi to mumbai?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a8b7709d-0d51-46c6-9959-7294c45c0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_prompt\n",
    "    }\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5134da9d-074a-44ca-b3ed-eb377c301b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KV5TjD8sN7gRyE5xFAXW8HUAkuCE', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"DEL\",\"loc_destination\":\"BOM\"}', name='get_flight_info'), tool_calls=None))], created=1714673087, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=22, prompt_tokens=88, total_tokens=110))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c213b0b7-93dc-4758-840c-e8dad0f86223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"DEL\",\"loc_destination\":\"BOM\"}', name='get_flight_info'), tool_calls=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32728813-9550-4e1f-a64a-fafce049c83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"DEL\",\"loc_destination\":\"BOM\"}'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427267f-9776-4f73-9c23-2e1ccb5e2e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a827ab3-786d-4527-958f-7eb35e967d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call realtime API : here we use a function to mimic the behavior of an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "51daeef8-1853-4a3b-939e-fb2da9279344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"airline\": \"KLM\",\n",
    "        \"flight\": \"KL643\",\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d97b4672-2ceb-4f38-af58-c51cab2adcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1b7e8b52-3457-4ed6-8a1c-dc5aabffaa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'DEL', 'loc_destination': 'BOM'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "77527550-2829-4a0e-969f-c52fca6090c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEL'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "74c11f02-b5ba-4846-a75c-bb19f08262a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOM'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get('loc_destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a424b03-eea7-4037-92d5-b0f24eafccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "637bf830-869e-42bd-8b13-2908269eec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca1d1dcc-4eb2-49cc-9d26-bb5a7e0fbc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d7559bb0-3653-4a84-930a-80cc200410da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_flight_info(loc_origin, loc_destination)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fc3d3968-92ae-487c-bbf6-db0c1a5deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equivalent to line below\n",
    "#chosen_function=eval(response2.choices[0].message.function_call.name)\n",
    "#flight = chosen_function(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d42086e5-e368-4362-8af0-4a5fe5672cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = get_flight_info(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e57329af-3c0d-434e-b1e4-f6b05eda4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"DEL\", \"loc_destination\": \"BOM\", \"datetime\": \"2024-05-03 01:42:10.850772\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "599d875f-117e-4355-ba51-246ca8b92816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When's the next flight from new delhi to mumbai?\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6eb1e2c0-5da2-47b2-ab1b-fc642cc5c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "96325d3a-fe5a-465a-83c1-3d1e21c7a5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\": \"DEL\", \"loc_destination\": \"BOM\", \"datetime\": \"2024-05-03 01:42:10.850772\", \"airline\": \"KLM\", \"flight\": \"KL643\"}'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0ceeca33-7d1b-4bfa-b2ff-8b2c24807391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls the def get_flight_info function\n",
    "\n",
    "#same code can be written as with one line change \n",
    "#{\"role\": \"function\", \"name\": response2.choices[0].message.function_call.name, \"content\": flight}\n",
    "\n",
    "#also last two lines which include functions=function_descriptions can be ommitted\n",
    "\n",
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\",\"content\": user_prompt},\n",
    "    {\"role\": \"function\", \"name\": 'get_flight_info', \"content\": flight}\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "58a09b87-ec27-450a-bf20-9be4dc76a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KcYxdv7yjqd4fExNW21TMriTIbNc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from New Delhi (DEL) to Mumbai (BOM) is on May 3, 2024, at 01:42:10. The flight is operated by KLM with flight number KL643.', role='assistant', function_call=None, tool_calls=None))], created=1714701823, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_a450710239', usage=CompletionUsage(completion_tokens=47, prompt_tokens=144, total_tokens=191))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a0165a07-1311-4054-9f31-ae5762e4962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from New Delhi (DEL) to Mumbai (BOM) is on May 3, 2024, at 01:42:10. The flight is operated by KLM with flight number KL643.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a29aa-1c0e-4101-8be3-ec54f187892f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7128db21-a313-42d5-a181-c2369f406693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_flight_info', 'description': 'Get flight information between two locations', 'parameters': {'type': 'object', 'properties': {'loc_origin': {'type': 'string', 'description': 'The departure airport, e.g. DUS'}, 'loc_destination': {'type': 'string', 'description': 'The destination airport, e.g. HAM'}}, 'required': ['loc_origin', 'loc_destination']}}, {'name': 'book_flight', 'description': 'Book a flight based on flight information', 'parameters': {'type': 'object', 'properties': {'loc_origin': {'type': 'string', 'description': 'The departure airport, e.g. DUS'}, 'loc_destination': {'type': 'string', 'description': 'The destination airport, e.g. HAM'}, 'datetime': {'type': 'string', 'description': 'The date and time of the flight, e.g. 2023-01-01 01:01'}, 'airline': {'type': 'string', 'description': 'The service airline, e.g. Lufthansa'}}, 'required': ['loc_origin', 'loc_destination', 'datetime', 'airline']}}, {'name': 'file_complaint', 'description': 'File a complaint as a customer', 'parameters': {'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'The name of the user, e.g. John Doe'}, 'email': {'type': 'string', 'description': 'The email address of the user, e.g. john@doe.com'}, 'text': {'type': 'string', 'description': 'Description of issue'}}, 'required': ['name', 'email', 'text']}}]\n"
     ]
    }
   ],
   "source": [
    "function_descriptions_multiple = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DUS\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. HAM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"book_flight\",\n",
    "        \"description\": \"Book a flight based on flight information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DUS\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. HAM\",\n",
    "                },\n",
    "                \"datetime\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The date and time of the flight, e.g. 2023-01-01 01:01\",\n",
    "                },\n",
    "                \"airline\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The service airline, e.g. Lufthansa\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\", \"datetime\", \"airline\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"file_complaint\",\n",
    "        \"description\": \"File a complaint as a customer\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the user, e.g. John Doe\",\n",
    "                },\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email address of the user, e.g. john@doe.com\",\n",
    "                },\n",
    "                \"text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Description of issue\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"name\", \"email\", \"text\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(function_descriptions_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b047dd6e-9cfc-48dc-8fc8-a7736274ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When's the next flight from Amsterdam to New York?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "87fe0805-1339-42a3-b87b-52d82751acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        # add function calling\n",
    "        functions=function_descriptions_multiple,\n",
    "        function_call=\"auto\",  # specify the function call\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "50fe4b98-72aa-419f-aa64-d9f3969df2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9KcjQJ57DKagm7Wthze3kZ6hMxA6p', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"AMS\",\"loc_destination\":\"JFK\"}', name='get_flight_info'), tool_calls=None))], created=1714702472, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=22, prompt_tokens=251, total_tokens=273))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3b20e32a-132a-4e24-9ecb-c68ca16bc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.loads(completion.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "19d0cd74-2baa-4264-b621-6e75e74a1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = json.loads(completion.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a4a4296d-546b-4ae2-b5df-bc42615dc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function = eval(completion.choices[0].message.function_call.name)\n",
    "#calls the outer get_flight_info that was defined explicitly earlier\n",
    "flight = chosen_function(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e803bb44-4d7e-4811-809f-83abaddd79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS\n",
      "JFK\n",
      "{\"loc_origin\": \"AMS\", \"loc_destination\": \"JFK\", \"datetime\": \"2024-05-03 09:55:32.510018\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "print(origin)\n",
    "print(destination)\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3b603436-bcff-4273-a7db-ae475d7e960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 09:55:32.510018\n",
      "KLM\n"
     ]
    }
   ],
   "source": [
    "flight_datetime = json.loads(flight).get(\"datetime\")\n",
    "flight_airline = json.loads(flight).get(\"airline\")\n",
    "\n",
    "print(flight_datetime)\n",
    "print(flight_airline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "97962e2b-0218-4c28-9e30-69f597f05f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Book a new flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ef036d2a-fefc-4953-8bb5-0e7ac20a6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"I want to book a flight from {origin} to {destination} on {flight_datetime} with {flight_airline}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ea34b078-334f-46df-a16e-d24938e34c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        # add function calling\n",
    "        functions=function_descriptions_multiple,\n",
    "        function_call=\"auto\",  # specify the function call\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d7a00a01-b835-4a56-9625-5b9fd8d330ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"AMS\",\"loc_destination\":\"JFK\",\"datetime\":\"2024-05-03 09:55:32.510018\",\"airline\":\"KLM\"}', name='book_flight'), tool_calls=None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "123e4e0b-9100-4331-8f2c-ce9d75570254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMS'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b6489ac2-1098-49e7-9ce4-5a02efb965f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JFK'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d503f0ea-5d81-40d0-8dcd-ddb8b37182f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-05-03 09:55:32.510018'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.function_call.arguments).get(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08ec0bf7-e8a8-4b1b-ac22-7b7d7135ad2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KLM'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.function_call.arguments).get(\"airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bb05763d-154b-4b2a-995e-818418691a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: File a complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "869087ec-4110-41c9-8e24-5eeeed9980af",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"This is John Doe. I want to file a complaint about my missed flight. It was an unpleasant surprise. Email me a copy of the complaint to abcd@xyz.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "20825319-8f37-4b10-9575-f6a0b654a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    " completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        # add function calling\n",
    "        functions=function_descriptions_multiple,\n",
    "        function_call=\"auto\",  # specify the function call\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "76e8036b-bc38-4eeb-8fa6-0f675b8a7fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"John Doe\",\"email\":\"abcd@xyz.com\",\"text\":\"I would like to file a complaint about my missed flight. It was an unpleasant surprise. Please investigate the matter and provide me with a resolution as soon as possible.\"}', name='file_complaint'), tool_calls=None)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "41d00850-549d-4b9b-b581-bd4262e4efc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"John Doe\",\"email\":\"abcd@xyz.com\",\"text\":\"I would like to file a complaint about my missed flight. It was an unpleasant surprise. Please investigate the matter and provide me with a resolution as soon as possible.\"}'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe27d6-4281-4819-81c4-22bb3f14d2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e07cc-bb97-4e97-b24e-145ea6458309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e57302b1-ed85-4ca8-92b1-9f1e87afbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function calling LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5bbb857b-e026-4318-b93c-ac206c3be9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f88dec66-79ef-41c4-8b24-7e0dc80ab304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b9ce70f6-ae1f-49b5-8006-968840637094",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f2acf110-7d43-429c-aa3c-35b0a84b5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt=\"can you tell me total number of countries in Asia ? Can you give me the name of the top 10 biggest countries ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "978a42c6-01da-423f-a35e-cc57935226a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThere are 48 countries in Asia.\\n\\nThe top 10 biggest countries in Asia, ranked by total land area, are:\\n\\n1. Russia\\n2. China\\n3. India\\n4. Kazakhstan\\n5. Saudi Arabia\\n6. Iran\\n7. Mongolia\\n8. Indonesia\\n9. Pakistan\\n10. Turkey'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "51f110c3-b79c-43ca-b21b-3a2d73af7ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 countries in Asia.\n",
      "\n",
      "The top 10 biggest countries in Asia, by land area, are:\n",
      "\n",
      "1. Russia\n",
      "2. China\n",
      "3. India\n",
      "4. Kazakhstan\n",
      "5. Saudi Arabia\n",
      "6. Iran\n",
      "7. Mongolia\n",
      "8. Indonesia\n",
      "9. Pakistan\n",
      "10. Turkey\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(prompt).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1b691a44-6503-46b6-98d6-7f12bc5be76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=\"can you tell me a capital of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2ef2cc56-7ac9-4058-a5dd-54e5e5155bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ff863bb6-f98d-49de-8fe7-ada8db386da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3=\"what are tokens and vectors  ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e7e983d1-9c2a-42ec-a680-ecdf8b67b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokens and vectors are both commonly used in the field of Natural Language Processing (NLP).\\n\\nTokens refer to individual units of text that have been identified and separated from a larger body of text. This could include words, phrases, or symbols. Tokens are often used as the building blocks for further analysis and processing in NLP tasks.\\n\\nVectors, on the other hand, are mathematical representations of tokens or groups of tokens. They are typically created using techniques such as word embedding, which maps words or phrases to numerical vectors based on their context and relationships with other words in a corpus of text. Vectors can be used to perform various NLP tasks such as text classification, sentiment analysis, and machine translation.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42e38f-29b1-430a-bcf4-73f54bf079e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "32775d1e-ecfd-42d0-985e-2e6c6067486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4bbeef55-e898-4ab0-9756-484bfcdb38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "07645647-cc63-443b-a195-c8d187d63c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"can you tell me the capital of {country}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f5d7f6ac-f996-4610-8fe1-93c4c3dcc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmt1=prompt_template_name.format(country=\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7d71acfe-0e6f-468c-9bf2-12ad0faf7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmt2=prompt_template_name.format(country=\"china\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "39f223be-445c-4a73-b419-534db763935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(propmt1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ebe2d98f-b7e6-4ee9-bc69-e3eb199d6c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of China is Beijing.'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(propmt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f1dbe9ae-411f-4dbb-8564-c66c76644349",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(\"what is a good name for a company that makes a {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5230106b-0faa-4116-b49a-7f230ee8513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3=prompt.format(product=\"electric cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "99b8f2d0-d423-4873-bde6-28fe71732e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.invoke(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "36e40b24-c2c0-4ff2-ad08-6836ad0140f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "add0e82f-dd93-4d9e-bc3a-889ad4a5b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "198da7b5-03a5-46fb-9f1c-065e88384119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcoDrive Electric Co.\n"
     ]
    }
   ],
   "source": [
    "print(res.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370a443-aea2-40cb-93e3-e6879ae6f4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ecb73661-59e1-4b98-a2c3-df310ed8a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2ca87b99-260a-46fe-9996-7d3844a207b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4=\"can you tell me who won the recent cricket world cup?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "56223bc8-b262-4fce-afb5-a56ecc5793c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The recent cricket world cup was won by England in 2019.'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt4).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b2e57eb6-d9f2-49fb-bcff-3308e1ba3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5=\"can you tell me current GDP of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8eaaa91d-302c-42a1-a716-47f8cc613383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current GDP of India (as of 2021) is approximately $2.7 trillion.'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt5).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7249647c-3694-4e42-9ca8-61f80b21f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do not get most recent info as LLM isn't trained on most recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e08617-dfbd-4db2-b31a-ec0953811915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a1f65ecf-1053-4c60-b8a8-28a0aef63071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use real time info we use SERP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3b588a27-7585-42f9-a065-7f56835a7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=da301176c057ed98e9b79bfbfb8d3c903ea3b899eec218b1f95fd753aee497f0\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\29\\75\\71\\9bf68178a74593837f73b6e9d9a070d45d308bddfd2e95290a\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "d22d74f3-099a-4340-a40b-2ea38bc1047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "84ddbee9-7afd-4ded-be8f-39dff037a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "329d7610-07eb-4837-9ec6-857b730bcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SearchAPI documentation : https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/utilities/searchapi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cb6ceba9-cc47-418b-8b9b-cb4fd088aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchapi_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "3b2df411-92a6-4843-9688-128881ed8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SEARCHAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "86b3fd5e-e87f-4148-9d81-e45207fe6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SearchApiAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "105552b3-93d8-46d4-8f33-3be4b0cae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SearchApiAPIWrapper(searchapi_api_key= searchapi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5fc2decd-8f33-4f44-9285-060d0691d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Hussein Obama II'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "589d6399-d854-4085-8ee8-bbd27afa9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"searchapi\"], searchapi_api_key= searchapi_key, llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "aebbc531-f803-488e-9576-508c57137d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "407de329-fbc5-4939-b845-0f02dcc105ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "262c9846-3512-482e-86c4-116790b83347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the searchapi to find the answer.\n",
      "Action: searchapi\n",
      "Action Input: \"cricket worldcup winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Australia men's national cricket team represents Australia in men's international cricket. As the joint oldest team in Test cricket history, playing in the first ever Test match in 1877, the team ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is not the most recent worldcup result. I should narrow down my search.\n",
      "Action: searchapi\n",
      "Action Input: \"recent cricket worldcup winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMost recently, the 2023 Cricket World Cup, hosted by India, was won by Australia, who beat India. The current trophy was instituted in 1999. It always remains ...\n",
      "Australia became the new World Cup 2023 winner by defeating India in the final match. In the final match, India played first and scored 240 runs, after that ...\n",
      "Australia has won the tournament six times, India and West Indies twice each, while Pakistan, Sri Lanka and England have won it once each. The best performance ...\n",
      "Recent News ; 2007, Australia, 2814 ; 2011, India, 2774 ; 2015, Australia, 1863 ; 2019, England, 241 ...\n",
      "England is the winner of the last World Cup tournament held in 2019 and is the trophy's current champion. They are the first hosting country to ...\n",
      "Australia won a record-extending sixth men's Cricket World Cup on Sunday, defying the odds and a partisan home crowd in Ahmedabad, to defeat ...\n",
      "World Cup trophy team series results, cricket records by trophy only on ESPNcricinfo.Check stats and records of World Cup trophy team series results.\n",
      "Australia won their sixth ODI World Cup title after beating hosts India in the final of the 2023 World Cup in Ahmedabad. India were unbeaten ...\n",
      "Pakistan and Sri Lanka have won one tournament each. Sri Lanka (1996) and India (2011) are the only hosts to win, when they co-hosted the tournament.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is the most recent result, but it seems there is some conflicting information. I should verify with another source.\n",
      "Action: searchapi\n",
      "Action Input: \"recent cricket worldcup winner 2023\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023 Cricket World Cup ; 1,250,307 (26,048 per match)  India Virat Kohli  India Virat Kohli (765)  India Mohammed Shami (24)  cricketworldcup.com.\n",
      "2023 Cricket World Cup final ; Australia won by 6 wickets ; Australia won by 6 wickets  19 November 2023  Narendra Modi Stadium, Ahmedabad  Travis Head (Aus).\n",
      "Australia are champions for a sixth time after they beat India by six wickets in the ICC Cricket World Cup 2023 final in Ahmedabad.\n",
      "Australia won a record-extending sixth men's Cricket World Cup on Sunday, defying the odds and a partisan home crowd in Ahmedabad, to defeat ...\n",
      "Australia became the new World Cup 2023 winner by defeating India in the final match. In the final match, India played first and scored 240 runs, after that ...\n",
      "Series result, Australia won the 2023/24 ICC Cricket World Cup ; Match number, ODI no. 4705 ; Hours of play (local time), 14.00 start, First Session 14.00-17.30, ...\n",
      "Official Cricket World Cup website - live matches, scores, news, highlights, commentary, rankings, videos and fixtures from the International Cricket ...\n",
      "England is the current T20 World Cup champion. They defeated Pakistan in the final of the 2022 tournament. Who is the highest run scorer in T20 ...\n",
      "Australia halt India juggernaut to win sixth World Cup ... [1/21]Cricket - ICC Cricket World Cup 2023 - Final ... recent victory in the World Test ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This result seems to be the most consistent and reliable. I now know the final answer.\n",
      "Final Answer: Australia is the winner of the most recent Cricket World Cup tournament, held in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Australia is the winner of the most recent Cricket World Cup tournament, held in 2023.'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell who won the cricket worldcup recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "bbc61845-fefa-465f-85ac-f069a0dea23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search API to find the current date and the temperature in Delhi yesterday\n",
      "Action: searchapi\n",
      "Action Input: \"current date and temperature in Delhi yesterday\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNew Delhi Weather History for the Previous 24 Hours ; 78 F  82 F  89 F ...\n",
      "Conditions, Comfort. Time, Temp, Weather, Wind, Humidity, Barometer, Visibility. 10:53 am. Mon, Apr 29, 67 F, Sunny. 16 mph, , 44%, 30.05 \"Hg, 10 mi.\n",
      "6:30 PM, 54 F, 48 F, 82 %, WSW, 8 mph, 0 mph, 29.31 in, 0.0 in, Mist. 7:00 PM, 54 F, 48 F, 82 %, W, 7 mph, 0 mph, 29.31 in, 0.0 in, Mist.\n",
      "New Delhi, Delhi, India Weather Historystar_ratehome ; 91, 91, 91 ; 83.17, 83.17, 83.17.\n",
      "Today's temperature in Delhi is 34c. Day's maximum temperature would hover at 34c, while minimum temperature is predicted to be 25c.\n",
      "Rise 2:28 AM. Set 1:52 PM. Temperature History. 5/3. High. Low. Forecast. 101. 79. Average. 102. 75. Last Year. 90. 68. Further Ahead. Hourly  Daily.\n",
      "Today's minimum temperature in Delhi is recorded at 27c (degrees celsius), and the maximum temperature is expected to go as high as 39c (degrees celsius).\n",
      "New Delhi Temperature Yesterday. Maximum temperature yesterday: 33 C (at 14:30) Minimum temperature yesterday: 22 C (at 05:30)\n",
      "As per the seven-day weather prediction, the temperature in Delhi is likely to reach 27 degrees Celsius on Friday, 32 degrees Celsius on Saturday, 32 degrees ...\n",
      "Past 24 hours in New Delhi The weather during the last hours ; 18:30 ; Mist ; 34C ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that I have the current date and temperature in Delhi yesterday, I can easily find the answer to the original question.\n",
      "Final Answer: The date today is May 3rd and the temperature in Delhi yesterday was 33C maximum and 22C minimum. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The date today is May 3rd and the temperature in Delhi yesterday was 33C maximum and 22C minimum.'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the date today and what was the temperature in Delhi yesterday ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b57eb467-8709-4f13-a844-d53034f32999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11704 sha256=0ee8f4161192f80c62e68049c7f969aba26a5b84b41934b93d677a67ef21d531\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\07\\93\\05\\72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "94252fb7-1c77-46e3-8672-d8213e9b45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7182add6-546b-4386-9cde-3f6596336434",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e1640ac8-b93b-4c71-9307-24706c8e5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should try using Wikipedia to get information about the general elections in India\n",
      "Action: wikipedia\n",
      "Action Input: India general elections\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elections in India\n",
      "Summary: India has a parliamentary system as defined by its constitution, with power distributed between the union government and the states. India's democracy is the largest democracy in the world.\n",
      "The President of India is the ceremonial head of state of the country and supreme commander-in-chief for all defense forces in India. However, it is the Prime Minister of India, who is the leader of the party or political alliance having a majority in the national elections to the Lok Sabha (Lower house of the Parliament). The Prime Minister is the leader of the legislative branch of the Government of India. The Prime Minister is the chief adviser to the President of India and the head of the Union Council of Ministers.\n",
      "India is regionally divided into States (and Union Territories) and each State has a Governor who is the state's head, but the executive authority rests with the Chief Minister who is the leader of the party or political alliance that has won a majority in the regional elections otherwise known as State Assembly Elections that exercises executive powers in that State. The respective State's Chief Minister has executive powers within the State and works jointly with the Prime Minister of India or their ministers on matters that require both State and Central attention. Some Union Territories also elect an Assembly and have a territorial government and other (mainly smaller) Union Territories are governed by an administrator/lieutenant governor appointed by the President of India.\n",
      "The President of India monitors the rule of law through their appointed governors in each State and on their recommendation can take over the executive powers from the Chief Minister of the State, temporarily when the elected representatives of the State government have failed to create a peaceful environment and has deteriorated into chaos. The President of India dissolves the existing State government if necessary, and a new election is conducted.\n",
      "\n",
      "\n",
      "\n",
      "Page: 2014 Indian general election\n",
      "Summary: General elections were held in India in nine phases from 7 April to 12 May 2014 to elect the members of the 16th Lok Sabha. With 834 million registered voters, they were the largest-ever elections in the world until being surpassed by the 2019 elections. Around 23.1 million or 2.7% of the total eligible voters were aged 1819 years. A total of 8,251 candidates contested the 543 elected Lok Sabha seats. The average election turnout over all nine phases was around 66.40%, the highest ever in the history of Indian general elections.\n",
      "The results were declared on 16 May, 15 days before the 15th Lok Sabha completed its constitutional mandate on 31 May 2014. The counting exercise was held at 989 counting centres. The Bharatiya Janata Party (BJP) received 31% of the vote and won 282 seats, while its National Democratic Alliance won a total of 336 seats. The BJP's vote share was the lowest by a party winning a majority of seats since independence,  The BJP won 31.0% votes, while NDA's combined vote share was 38.5%. However, the governing coalition had the largest majority since the 1984 elections, and it was the first time since 1984 that a party had won enough seats to govern without the support of other parties.\n",
      "In contrast, the result was the worst-ever performance by the Indian National Congress (INC), which had ruled India for most of its post-independence history. The INC received 19.3% of the vote and won only 44 seats, with its wider alliance, the United Progressive Alliance, winning a total of just 59. In order to become the official opposition party in India, a party must have 55 seats; as a result, there was no official opposition party.\n",
      "\n",
      "\n",
      "\n",
      "Page: 2004 Indian general election\n",
      "Summary: General elections were held in India in four phases between 20 April and 10 May 2004. Over 670 million people were eligible to vote, electing 543 members of the 14th Lok Sabha. Seven states also held assembly elections to elect state government\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The ongoing general elections in India are being held in multiple phases and involve the election of members to the Lok Sabha and state governments. The most recent general election was held in 2014, with the next one scheduled for 2019.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The ongoing general elections in India are being held in multiple phases and involve the election of members to the Lok Sabha and state governments. The most recent general election was held in 2014, with the next one scheduled for 2019.'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell me about the ongoing general elections in India ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d430609-d3a0-46f9-a13f-36b3980bf471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d2dd2c-1917-4b97-9c36-63a4f7b24473",
   "metadata": {},
   "source": [
    "Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c4df9-999a-4346-869e-ad1100b92f57",
   "metadata": {},
   "source": [
    "Central to LangChain is a vital component known as LangChain Chains, forming the core connection among one or several large language models (LLMs). In certain sophisticated applications, it becomes necessary to chain LLMs together, either with each other or with other elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "87680e96-7c79-487d-84a4-f7d9a5a4f0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000002E07F89C100>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000002E07F8A1EE0>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "199874d7-939d-47b8-9125-bba5b931b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "26c7761f-98c7-4eeb-a7df-6df14bc5f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d770bc9b-0739-4ba8-822c-cafd3c2df7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2263d073-3986-407f-ac7f-fb1b086e869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. \"Apex Automotives\"\\n2. \"Velocity Motors\"\\n3. \"Prestige Performance\"\\n4. \"Elite Engineering\"\\n5. \"Luxury Motorworks\"\\n6. \"Revolution Racing\"\\n7. \"Supreme Supercars\"\\n8. \"Exotic Automotive Co.\"\\n9. \"Hyperdrive Motors\"\\n10. \"Infinite Innovations\"'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Supercar\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9656be-3db0-4c9e-96ab-8e55bca32a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "97c93224-7458-4d16-8f1f-f33e7a9b4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "132d4467-5301-4403-9341-11c06b0849f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"i want to open a restaurent for {cuisine} food, suggest a fency name for this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2a79c5ba-2269-48da-95be-b8bf0659b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['cuisine'], template='i want to open a restaurent for {cuisine} food, suggest a fency name for this')"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0f01befb-81df-4007-8342-ef0cd4c69eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "82db0fd3-8325-4a1a-9bce-ff730e73de2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Maharaja\\'s Palace: Fine Indian Cuisine\"'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"indian\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d667aacf-0b50-492c-94e2-61db19092a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "0b39b4e3-333b-485b-9018-974219cc08b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mi want to open a restaurent for american food, suggest a fency name for this\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"The Stateside Bistro\"'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"american\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fa8f6-e57b-467d-bea6-b85fbafae618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2a883d38-8ce2-41e3-b3a5-56a05369863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want to combine multiple chain and set a seqence for that we use simplesequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "b9998448-f2f5-42f4-8eef-6a46f39a4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "input_variables=[\"purpose\"],\n",
    "    template=\"I want to start a startup for {purpose} , suggest me a city in India for this\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "987a0e0d-637d-4df9-8b24-9c1d4f6930d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "73648ad9-0691-41a6-a510-a695f6fe37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items=PromptTemplate(\n",
    "input_variables=[\"city in India\"],\n",
    "    template=\"display the {city in India} and based on the {city in India} suggest some local cuisine ? \"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "e629ae48-3f90-4b77-8c75-61ded0616b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain=LLMChain(llm=client,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "86acb040-af9c-444e-b597-e508272f7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next.\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "31da7397-cba6-4f48-b90b-66dc603b6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "36670dde-6909-463b-aef8-574ac7b54ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Some popular local cuisines in Bangalore include South Indian dishes like dosa, idli, and vada, as well as North Indian dishes like biryani and butter chicken. Other popular local dishes include masala dosa, chicken ghee roast, and akki roti. Bangalore also has a thriving street food scene, with popular dishes like chaat, vada pav, and momos. Additionally, the city has a large vegetarian population, resulting in a variety of vegetarian dishes like sambar, rasam, and paneer dishes.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"food delivery\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2ff81-dad7-46d2-b4ec-79093c32324b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "05a1da1b-4338-4360-9ecb-ac6e8795db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SequentialChain : A more general form of sequential chains, allowing for multiple inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "8fbe681c-58a4-4faa-82ac-bc693003f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    template=\"i want to open a restaurant for {cuisine}, suggest a fancy name for it\"\n",
    ")\n",
    "\n",
    "name_chain=LLMChain(llm=client, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b4c5ce10-75c3-4360-9fbd-97dede1ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates_items=PromptTemplate( \n",
    "    input_variables=[\"restaurant_name\"],\n",
    "    template=\"suggest some menu items for {restaurant_name}\"\n",
    "    \n",
    ")\n",
    "\n",
    "food_items_chain=LLMChain(llm=client, prompt=prompt_templates_items, output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "575b2b22-bdc7-44d8-a534-556d4b3b4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a1fd006b-167b-44a3-9166-db790ead9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[name_chain, food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9d70d410-c53f-4d57-81cf-63369bac3c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Symphony\" ',\n",
       " 'menu_items': '\\n\\n1. Tandoori Chicken Skewers\\n2. Vegetable Samosas\\n3. Lamb Rogan Josh\\n4. Butter Chicken\\n5. Aloo Gobi (potato and cauliflower curry)\\n6. Palak Paneer (spinach and cheese curry)\\n7. Chicken Tikka Masala\\n8. Garlic Naan\\n9. Mango Lassi\\n10. Biryani (spiced rice dish)\\n11. Saag Paneer (spinach and cheese)\\n12. Chana Masala (chickpea curry)\\n13. Malai Kofta (vegetable dumplings in creamy sauce)\\n14. Dal Makhani (creamy lentil curry)\\n15. Gulab Jamun (sweet fried dough balls in syrup)'}"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b018d5-f53e-4fd1-871c-969e7f92f463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "a7a00856-4fcf-4a54-ae09-091ec7cccd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "cc13c94e-d5d2-4143-a446-f6d1dbe5579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pypdf is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "253caec1-e2ae-4600-a0c2-7004a1278edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\admin\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pypdf) (4.10.0)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/290.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 133.1/290.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "51f3ecbc-b06c-4466-97cb-34cce49e77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f24c09fe-bd0b-4928-9eca-7ba357964475",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "403561cb-3eaf-4916-9240-34df80b923d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x2e07ff52e80>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "c5d6c938-e9d9-4f7a-b7da-d4408b836177",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d0b0f59c-53a3-4ef3-ae0a-dcd098b2b936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/355917108\\nNeu ral Machine T ranslation with Attention\\nTechnic al R eport   August 2021\\nDOI: 10.13140/RG.2.2.29381.37607/1\\nCITATIONS\\n0READS\\n3,753\\n2 author s:\\nMohammad W asil Saleem\\nUniv ersitt P otsdam\\n3 PUBLICA TIONS \\xa0\\xa0\\xa01 CITATION \\xa0\\xa0\\xa0\\nSEE PROFILE\\nSandeep Upr ety\\nUniv ersitt P otsdam\\n1 PUBLICA TION \\xa0\\xa0\\xa00 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Sandeep Upr ety on 05 No vember 2021.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 0}),\n",
       " Document(page_content='Neural Machine Translation with Attention\\nMohammad Wasil Saleem\\nMatrikel-Nr.: 805779\\nUniversit at Potsdam\\nsaleem1@uni-potsdam.deSandeep Uprety\\nMatrikel-Nr. 804982\\nUniversit at Potsdam\\nuprety@uni-potsdam.de\\nAbstract\\nIn recent years, the success achieved\\nthrough neural machine translation has\\nmade it mainstream in machine translation\\nsystems. In this work, encoder-decoder\\nwith attention system based on Neural\\nMachine Translation by Jointly Learning\\nto Align and Translate by Bahdanau et al.\\n(2014) has been used to accomplish the\\nMachine Translation between English and\\nSpanish Language which has not seen\\nmuch research work done as compared\\nto other languages such as German and\\nFrench. We aim to demonstrate the re-\\nsults similar to the breakthrough paper on\\nwhich our work is based on. We achieved\\na BLEU score of 25.37, which was close\\nenough to what Bahdanau et al. (2014)\\nachieved in their work.\\n1 Introduction\\nMachine Translation (MT) is the task of translat-\\ning text without human assistance while preserv-\\ning the meaning of input text. The early approach\\nto machine translation relied heavily on hand-\\ncrafted translation rules and linguistic knowledge.\\nStarted in early around 1950s, unlike rule-based\\nmachine translation, Statistical machine transla-\\ntion (SMT) generated translations based on statis-\\ntical models whose parameters are derived from\\nthe analysis of bilingual text corpora (Koehn et al.,\\n2003). Though reliable, for SMT, it can be hard\\nto nd content for obscure languages and is less\\nsuitable for language pairs with big differences\\nin word order making the quality of translation\\nfar from satisfactory. With the progress in deep\\nlearning being applied to MT, in 2014, end-to-end\\nneural network translation model was proposed\\nby (Bahdanau et al., 2014; Sutskever et al., 2014)\\nwhere the term neural machine translation wasformally used. Neural machine translation (NMT)\\nis the newest method of MT that uses a single\\nlarge neural network to model the entire transla-\\ntion process, freeing the need for excessive fea-\\nture engineering. Through the rapid research and\\nbreakthroughs, end-to-end neural machine trans-\\nlation has gained remarkable performances (Shi\\net al., 2021; Bahdanau et al., 2014) and have be-\\ncome mainstream approach to MT.\\n2 Related Work\\nEarly problem of NMT was often the poor trans-\\nlation for long sentences (Sutskever et al., 2014)\\nwhich can be attributed to the xed-length of\\nsource encoding in conventional encoder-decoder\\nas suggested by Cho et al. (2014a) for which the\\nconcept of attention to NMT was introduced by\\nBahdanau et al. (2014) to avoid keeping a xed\\nsource side representation.\\nAs compared to separately tuned components in\\nSMT, newly emerging Neural Machine translation\\nradically departures from previous machine learn-\\ning approaches as the training of NMT is end-to-\\nend which has signicantly improved translation\\nquality across 30 different languages (Junczys-\\nDowmunt et al., 2016). NMT model can be attrac-\\ntive for various reason one being scalability issue,\\nwhether it be memory requirements or computa-\\ntional speed. Another being able to train all the\\ncharacter embedding as each characters frequently\\noccurs in the training corpus.\\nMost neural machine translation models pro-\\nposed use encoder-decoder where a neural net-\\nwork reads and encodes a source sentence into\\na xed-length vector and a decoder then outputs\\na translation from the encoded vector, where in\\nmost of the cases the encoder and decoder are\\nmainly implemented as RNNs, CNNs or self-\\nattention network (Wu et al., 2018). The whole\\nencoderdecoder system, which consists of the\\nencoder and the decoder for a language pair, is', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 1}),\n",
       " Document(page_content='jointly trained to maximize the probability of a\\ncorrect translation given a source sentence (Bah-\\ndanau et al., 2014). After the initial proposal by\\n(Sutskever et al., 2014; Bahdanau et al., 2014),\\nmuch work has been done on the sequence-to-\\nsequence neural machine translation model rang-\\ning from new attention mechanism (Luong et al.,\\n2015) to working on the problem of out-of-\\nvocabulary words (Jean et al., 2015) for which se-\\nquential RNNs are used both for encoding source\\nsentences and generating target translation.\\nWe draw our inspiration for machine transla-\\ntion with attention from Bahdanau et al. (2014).\\nWe have chosen to base our project on this paper\\nas attention mechanism has been widely used as\\nbaseline and is thoroughly studied among the NLP\\ncommunity.\\n3 Model\\nMachine Translation is equivalent to maximizing a\\nconditional probability of a target sentence given\\nthe source sentence. In Neural Machine Trans-\\nlation, we parameterize it to maximise the condi-\\ntional probability. The approach used by Cho et al.\\n(2014b) was to encode the source sentence into\\na xed-length vector, which becomes difcult to\\ncompress all the necessary information into a xed\\nlength vector, which makes it difcult for the Neu-\\nral Network to handle long sentences, and thus the\\nperformance of the encoder-decoder drops as the\\nlength of the sentences increases. So we use the\\nmodel proposed by Bahdanau et al. (2014), where\\nit does not encode the input sentence into a xed-\\nlength vector, rather than it simply encodes the in-\\nput sentence into sequence of vectors, and while\\ndecoding the translation, it select subset of vectors\\nfrom the using attention mechanism. And Bah-\\ndanau et al. (2014) showed that encoder decoder\\nmodel with attention mechanism cope better with\\nlong sentences. In the next section, we will rst\\ngive a brief introduction on encoder-decoder, the\\nRNN, and one of its type, GRU, the one we used\\nin our model and nally the attention mechanism.\\n3.1 Encoder-Decoder\\nEncoder-Decoder, rst proposed by Cho et al.\\n(2014b), basically consists of 2 parts, the encoder\\nand the decoder. Encoder codes the sequence\\nof input sentence into dense vector representa-\\ntion, and then decoder takes in the encoded sen-\\ntence and decode the representation into anothersequences of words. They are trained to maximize\\nthe conditional probability of the output sentence,\\ngiven the input sentence.\\nRNN is necessary when we need to maintain the\\nword order in a sentence. This is not handled by\\nbags of words model or other statistical models. In\\naddition to input, xiand output yi, we also have a\\nstate vector, ai, which is initialized with vectors of\\nzeros.iwould be the ithtimestep In the rst layer\\nof RNN, the input and state vector is fed into the\\nrecurrent unit, the recurent unit may look like1:\\nat=f(Waaat1+Waxxi),\\nand,\\nyt=g(Wyaat)\\nwhere, t is the time step, Waais the weights be-\\ntween two hidden layer, Waxis the weight be-\\ntween input and hidden layer, and Wyais the\\nweight between hidden and the output layer, and\\nfcan betanh orRelu activation function, and g\\ncan besigmoid orsoftmax activation function.\\nAfter feeding the input to rnn unit, it returns a new\\nstate vector in the next time step. This new state\\nvector will be mapped to the output vector using\\nsome function. This output vector can be used as\\na prediction. The new state vector is cached and is\\npassed across the next unit of the RNN, along with\\nthe input in order for it to return the next state vec-\\ntor. This happens recursively for all the input ele-\\nments. So, when the model is reading the second\\nword, instead of just predicting output using only\\nthe second word, it also gets information from the\\nprevious time step (rst word) in terms of the state\\nvector.\\nOne of the problem of RNN is that it runs into\\nthe problem of Vaishing gradient, rst described\\nby Hochreiter (1998). This happens when we have\\na very long sentence, which tends to have long\\nterm dependencies. That means a word at the end', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 2}),\n",
       " Document(page_content='the problem of Vaishing gradient, rst described\\nby Hochreiter (1998). This happens when we have\\na very long sentence, which tends to have long\\nterm dependencies. That means a word at the end\\nof the sentence would be semantically dependent\\non the word occurring at the beginning of the sen-\\ntence. So, the gradients during the backpropaga-\\ntion step would have a very hard time propagating\\nback to affect the words or weights of the earlier\\nunits. The gradients diminishes in the backpropa-\\ngation step and not able to reach the earlier units.\\nGenerally, RNN has local inuences where a word\\nis mainly inuenced by words closed to it. So that\\nmakes it difcult for the output at the later unit\\n1https://www.coursera.org/learn/nlp-sequence-\\nmodels/home/welcome', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 2}),\n",
       " Document(page_content='Figure 1: The left diagram represents Long Short Term Memory Unit, with ias an Input gate, oas an\\nOutput Gate, and fas a Forget Gate. The right diagram represents Gated Recurrent Unit, with ras Reset\\nGate, andzas an Update Gate. (Chung et al., 2014)\\nto be strongly inuenced by a word that was very\\nearly in the sequence.\\nBut we can further improve the training by us-\\ning other RNN units, like GRU (Chung et al.,\\n2014) or LSTM (Hochreiter and Schmidhuber,\\n1997), which are better at capturing long-range de-\\npendencies. The state vector in simple RNN can\\nbe considered as a memory, where the memory ac-\\ncess was not controlled. At each step, the entire\\nmemory state was read and updated. But in GRU\\nand LSTM, we use a gating mechanism to control\\nthe memory. Since, we used GRU in our model,\\nso we will only describe GRU here.\\nIn GRU, (Chung et al., 2014; Rana, 2016), the\\nactivationhj\\ntis a linear interpolation between the\\nprevious activation hj\\nt1and the candidate ativa-\\ntionhj\\nt:\\nhj\\nt= (1zj\\nt)hj\\nt1+zj\\nthj\\nt\\nwhere,zj\\ntis the update gate, that decides how\\nmuch GRU units updates its activation [See Fig.\\n1]. The update gate is given by :\\nzj\\nt=(Wzxt+Uzht1)j.\\nAnd the candidate activation hj\\ntis computed by :\\nhj\\nt=tanh (Wx t+U(rtht1))j,\\nwheredenotes element-wise multiplication and\\nrj\\ntare reset gates. When a reset gate at specic\\ntime, t is set to 0, i.e. rj\\nt== 0 , which makes the\\nGRU to forget the past, i.e. forget the previousstate vectors. This is considered same as reading\\nthe rst word of the input sentence. And nally,\\nwe can compute the reset gate by :\\nrj\\nt=(Wrxt+Urht1)j.\\nOne of the weakness of RNN is that it only uses\\ninformation that is earlier in the sequence to make\\npredictions but not the information which are later\\nin the sequence. When predicting the output at\\ntime step i, it does not use the word at time step i+1\\nor i+2 or any other words in the later time step. So,\\nit would be useful to know not just the information\\nfrom the words from the previous time step but\\nalso the information from the later time steps.\\nSo, we use Bidirectional RNN, rst proposed\\nby (Schuster and Paliwal, 1997). From a point\\nin time, it takes information from both the ear-\\nlier and later time step in the sequence. The\\nFirst RNN, which we called forward RNN, fis\\nfed the input sequence as it is. And the second\\nRNN, which is also called backward RNN, f\\nis fed the input sequence in reverse order. This\\ngives two separate state vectors  a forward state\\nvector, hT\\nj, and a backward state vector hT\\nj.\\n hT\\njwould be a sequence of forward hidden state\\nvectors, ( h1,..., hTx), and similarly, backward\\nstate vector hT\\njwould be a sequence of backward\\nhidden state vector, ( h1,..., hTx). And the out-\\nput at a specic timestep is accounted by the con-\\ncatenation of output of two RNNs, concatenating hjand hj, i.e.hj= [ hT\\nj, hT\\nj]. So, when pre-\\ndicting the output at a specic time step, it will', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 3}),\n",
       " Document(page_content='Figure 2: Attention Model (Luong et al., 2015)\\nuse the information from the past, present as well\\nas from the future. We need the entire sequence of\\ndata before we can make any predictions.\\nThe architecture that we are proposing here is\\nbased on the Encoder-Decoder Framework. The\\nencoder takes in the input sentence and converts\\nthem into a vector representation\\nThe encoder can be an RNN (Cho et al., 2014b)\\nor LSTM unit (Sutskever et al., 2014). They pro-\\ncesses the input sentence, pass it through RNN or\\nLSTM, and when it encounters the end of sen-\\ntence, then the hidden state, that captured all the\\nrelevant information passes it to the decoder. Then\\nthis information is used to predict the translations\\nin the decoder, which can be RNN or LSTM, until\\nit predicts the end of the sentence token. The hid-\\nden state needs to remember every word from the\\ninput sentence. So that is why this model tends to\\nwork for short sentences and not long sentences.\\nEven though if we used LSTM or GRU, which\\ntends to remember the words that occured very\\nearly in the sequence, it will still not be able to\\nlearn the alignment between the source word and\\nthe target word. They often forget the initial part\\nof the sentence once they are processed in the en-\\ncoder. That is why we use an alignment mecha-\\nnism called attention. They help to memorize this\\ninformation for longer sentences. But we need to\\nlearn this alignment. It can vary from language to\\nlanguage.3.2 Attention\\nIn this section, we will specically dene the\\nalignment mechanism, [See Figure 2] that we used\\nin our model. In RNN Encoder-Decoder model\\n(Sutskever et al., 2014), we faced with the bottle-\\nneck problem, where the complete sequence of in-\\nformation of the source sentence, must be captured\\nby one single vector, i.e. the last hidden unit of the\\nencoder RNN is used as a context vector for the\\ndecoder, which becomes difcult for the decoder\\nto summarise large input sequence at once. This\\nalso poses a problem where the encoder is not able\\nto memorize the words coming at the beginning\\nof the sentences, which leads to poor translation\\nof the source sentence. The Attention mechanism\\njust addresses this issue, by retaining and utilising\\nall the hidden state of the input sentence during the\\ndecoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out specic ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\nAttention to the relevant part of the input se-\\nquence.\\nThe rst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 4}),\n",
       " Document(page_content='Spanish en la estrategia 2020 , reconocimos el hecho de que , si queremos mantener nuestro\\nnivel de prosperidad en europa , tenemos que aumentar nuestra productividad .\\nEnglish in the 2020 strategy , we acknowledged the fact that , if we are to maintain our level\\nof prosperity in europe , we need to increase our productivity .\\nSpanish sin embargo , es algo que debemos hacer si queremos demostrar a los estados unidos\\nque nos deben considerar como un socio serio en la alianza contra el terrorismo .\\nEnglish yet do it we must , if we are to demonstrate to the usa that we are to be taken\\nseriously as a partner in an alliance against terrorism .\\nSpanish sabran ustedes que fue tambi en a instancias de esta c amara que la comisi on entabl o\\nnegociaciones , y estas han dado un resultado encomiable .\\nEnglish you will be aware that it was not least at the insistence of this house that the com-\\nmission entered into negotiations , and these have produced a creditable result .\\nTable 1: Examples of Spanish and English sentences from the dataset\\n(2015).\\nWe will only discuss the attention model, pro-\\nposed by Bahdanau et al. (2014). After the in-\\nput sequence is passed through the encoder, it pro-\\nduces hidden state for each of the elements in the\\nsequence (h1,...,h Tx). Then we multiply the de-\\ncoders hidden state at time step t (s1,...,s Ty),\\nwith all of the encoders hidden state, which gives\\nus the alignment score of each of the encoder out-\\nput with respect to the decoder input and hidden\\nstate at that time step:\\net= [sT\\nth1,...,sT\\nthTx]\\nThe alignment score quanties the amount of\\nAttention the decoder will place on each of the en-\\ncoder outputs when producing the next output, so\\ninstead of looking at the entire sequence, it just\\nconcentrate on few relevant parts of the sequence\\nwhen predicting the next word.\\nAfter calculating the alignment score, we pass\\nthe vectoretthrough the softmax layer, to calcu-\\nlate the probability distribution.\\nt=softmax (et)\\nThen we multiply each of the attention weights\\nwith each of the encoder hidden state, to get con-\\ntext vector,at\\nat=Tx\\ni=1t\\nihi\\nIf the attention score of specic element of the\\ninput sequence is close to 1, then its inuence on\\nthe decoder output at that specic time step in-\\ncreases. And then nally, the context vector atproduced will be concatenated with the decoder\\nhidden state, st, i.e.\\nht= [at,st]\\nand is fed into decoder RNN, which produces new\\nhidden state.\\n4 Data\\nWe used a Parallel Corpus for English-Spanish\\nlanguage, which was extracted from the proceed-\\nings of the European Parliament, also called Eu-\\nroparl dataset (Koehn, 2005). It contains 1.96\\nMillion sentences, each for English and Spanish.\\nMost common words and count for both languages\\nare shown below:\\nWords Count\\nde 1799827\\n, 1456229\\nla 1222089\\nque 992176\\n. 867284\\nen 790382\\nel 696521\\ny 692640\\na 577052\\nlos 548495\\nTable 2: SpanishWords Count\\nthe 1956558\\n, 1371506\\nof 932044\\nto 875415\\n. 864674\\nand 747108\\nin 622426\\nthat 476250\\na 430093\\nis 401782\\nTable 3: English\\nFirst we lter out all the sentences having words\\ngreater than 50. Then we sort these sentences\\nbased on the number of words in each of the sen-\\ntences, so that we have less padded sentences in\\nour initial indices and sentences with high padding\\nto be at the end of our indices, following with', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 5}),\n",
       " Document(page_content='usual tokenization methods. Only preprocessing\\nwe used was to lower case the words.\\nWe selected 1 million sentences for the model-\\ning due to the hardware constraints. We split the\\ndataset into usual format, i.e. train, test and vali-\\ndation. We used 900K sentences for our training,\\n80K for validation and remaining 20K sentences\\nfor the test set, which was not seen by the model\\nduring training. We did not limit the vocabulary\\nsize to any hard coded number, i.e. to get top N\\nmost frequent words. The vocabulary size we got\\nfrom English sentences was 36838 and for Span-\\nish was 63220. Only token we added was End of\\nSentence and Start of Sentence Tokens. We used\\nSpanish as a source sentence and English as a tar-\\nget sentence. See Table 1.\\n5 Experiments\\nThe encoder and decoder of our model have 256\\nhidden units each. The encoder consist of for-\\nward and backward gated recurrent unit (GRU)\\neach having 256 hidden units. The decoder has\\na single forward gated recurrent unit (GRU), with\\n256 hidden dimensions, unlike 1000 hidden units,\\nas in Bahdanau et al. (2014) due to the hardware\\nlimitations. And we only trained the model for\\nSpanish to English translation.\\nWe used Adam optimizer to train the model, and\\ngradient update is computed with a batch size of\\n32 sentences.\\nWe initialized our weights with xavier (Glo-\\nrot) initializations, (Glorot and Bengio, 2010) with\\nUniform Distribution, U[a,a], where\\na=\\n6\\nnin+nout\\nwhereninis the number of input neurons in the\\nweight tensor, and noutis the number of output\\nneurons in the weight tensor.\\nThe total number of trainable parameters were\\n43,564,519. We trained the model for roughly 20\\nhours. After our model was trained, we use greedy\\nsearch to predict the translation for the given input\\nsentence, that maximizes the conditional proba-\\nbility instead of using beam search as mentioned\\nin the paper Bahdanau et al. (2014) due to our\\nunfamiliarity and technical difculty dealing with\\nBeam search.\\nWe, then used BLEU (Papineni et al., 2002)\\nscore to evaluate how the model was working on\\nthe test data.6 Results\\n6.1 Quantitative Results\\nWe trained our model on maximum length of 50\\nsentences, so any length smaller than or equal to\\n50 is used for the training, We trained our model\\nuntil the error on the validation data or the devel-\\nopment data stops decreasing, in order to avoid\\nthe problem of overtting. We achieved a BLUE\\nscore of 25.76on the test data and the error rate for\\nSpanish to English translation was 4.267 on our\\ntest data. According to Bahdanau et al. (2014), we\\ncan say that our model out perform the encoder\\ndecoder model, proposed by Cho et al. (2014b),\\nfor 50 sentences, where they got BLEU score of\\n17.82. Their performance drops when the length\\nof the sentence is increased (Cho et al., 2014b).\\nSo, the limitation of using xed length vector\\nin simple encoder decoder model in Cho et al.\\n(2014b) work was the reason that it was under per-\\nforming with long sentences.\\nThis was our motivation to use the proposed ap-\\nproach by Bahdanau et al. (2014), where the per-\\nformance of the encoder-decoder with attention\\nshows no deterioration with sentence of length\\ngreater than 50 sentences. The result that we\\ngot which was 25.76 was quite close to the Bah-\\ndanau et al. (2014), where they got BLEU score of\\n26.75,training with 1000 encoder and decoder di-\\nmensions, and training on corpus of 384M words.\\nThey were also able to achieve BLEU score of\\n28.45 when trained the data until the performance\\nof the validation stopped improving.\\n6.2 Qualitative Results\\nThe model proposed by Bahdanau et al. (2014)\\nprovides a way to investigate the soft alignment\\nbetween the translated sentence from the model\\nand the input sentence. The matrix given in Fig\\n3, each of the cells represent the weights ijof\\nthe annotation of the j-th source word for the i-\\nth target word. This helps in visualizing and see\\nwhich word from the input sentence were con-\\nsidered more important for generating the target\\nword.', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 6}),\n",
       " Document(page_content='the annotation of the j-th source word for the i-\\nth target word. This helps in visualizing and see\\nwhich word from the input sentence were con-\\nsidered more important for generating the target\\nword.\\nWe see that majority of the weights are con-\\ncentrated on the diagonal matrix, along with non-\\nmonotonic alignments. The non-monotonic align-\\nments would be high for long sentences, since the\\nwords in long target sentence tends to have depen-\\ndence on more than one word in source sentence.', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 6}),\n",
       " Document(page_content='(a)\\n (b)\\n(c)\\n (d)\\nFigure 3: Alignments translated from Spanish to English by our model. The row represents the translated\\nsentence, English and the column represents the source sentence, Spanish. Each of the cells of the matrix\\nrepresents weights, ij, of the annotation of the j-th source word for the i-th translated word. (1:White,\\n0:Black)', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 7}),\n",
       " Document(page_content='Let us take an example from the test set, con-\\nsider the source sentence:\\nson los estados miembros de la zona del\\neuro los que no han cumplido , en espe-\\ncialla republica federal de alemania que\\nse niega a mantener su promesa.\\nAnd its translation by our model is :\\nthat it is the member states of the euro\\narea which have not complied honour,\\nparticularly the federal republic of ger-\\nmany that refuses to keep their promise\\nto sustain their promise.\\nAnd the reference is:\\nit is the member states of the euro area\\nthat have not delivered - and particu-\\nlarly the federal republic of germany,\\nwhich is refusing to keep its promise.\\nWe can observe from our translated sentence,\\nthe model generates have not complied  , instead\\nofhave not delivered (from reference sentence),\\nwhich has the same meaning. It tries to preserve\\nthe meaning of the whole sentence, and it does not\\nblindly takes the word from the reference, it tries\\nto generalize.\\nRefer to Table 4 at the end of the paper for\\nmore translations from Spanish to English using\\nEncoder Decoder model with Attention Mecha-\\nnism.\\n7 Discussion\\nAfter trying to achieve the result similar to what\\nwas presented in the paper, we are satised with\\nour result though there is much that can be im-\\nproved. Limitation caused by the hardware held\\nus back from achieving better results. We used the\\nserver provided by the university and as a backup\\nused google colab for our work, so we had to be\\nwary of the maintenance schedule happening in\\nthe server and the limitation of 24 hrs of work-\\ntime on google colab, which otherwise could in-\\nterrupt while we were training our model. So,\\nto overcome these challenges we decided to use\\n1M sentences from each form Spanish and English\\ndataset, and reduce the parameters for encoder-\\ndecoder.\\nWe also faced problem with length of the vo-\\ncabulary size of English and Spanish sentences,\\nwhere the vocabulary size of the English sen-\\ntence were the output dimension, and vocabularysize of Spanish sentence were input dimensions of\\nour model. This leads to increase in number of\\ntrainable parameters, the decoding complexity in-\\ncreases with number of target words (vocabulary\\nsize of the English), where this problem has been\\naddressed by Jean et al. (2015).\\n8 Conclusion\\nThe approach proposed by Cho et al. (2014b) was\\nto encode the whole sentence into xed length vec-\\ntor, and this becomes problematic when dealing\\nwith long sentences. We extend this basic encoder-\\ndecoder model by an Attention mechanism (Bah-\\ndanau et al., 2014), where the model searches for\\nthe input word computed from the encoder, which\\nbest align with the target word, when generat-\\ning each target word. This frees the model from\\nhaving to encode the source sentence into a xed\\nlength vector, only rely on the information rele-\\nvant for generating each target word. We com-\\npared our model for Spanish to English translation\\nwith both of these approaches, and found that our\\nmodel works better than the encoder-decoder ap-\\nproach (Cho et al., 2014b), and have slightly lower\\nresults than the architecture with Attention mech-\\nanism, (Bahdanau et al., 2014). We also observed\\nthat the model tries to align the target word with\\nthe relevant word from the translated sentence.\\nIn the future work, there are several things we\\ncan try. We can train our model on much larger\\ndataset, with a better hardware and with differ-\\nent attention models. We can also focus on how\\nto handle the stop words, punctuation, as we can\\nsee on Table 2 and Table 3, which accounts for\\nthe highest word count, and also to handle the un-\\nknown words, which does not appear in the train-\\ning data, but in the test data.\\nReferences\\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua\\nBengio. Neural machine translation by jointly\\nlearning to align and translate. arXiv preprint\\narXiv:1409.0473 , 2014.\\nKyunghyun Cho, B. V . Merrienboer, Dzmitry\\nBahdanau, and Yoshua Bengio. On the\\nproperties of neural machine translation: En-', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 8}),\n",
       " Document(page_content='learning to align and translate. arXiv preprint\\narXiv:1409.0473 , 2014.\\nKyunghyun Cho, B. V . Merrienboer, Dzmitry\\nBahdanau, and Yoshua Bengio. On the\\nproperties of neural machine translation: En-\\ncoderdecoder approaches. In SSST@EMNLP ,\\n2014a.\\nKyunghyun Cho, B. V . Merrienboer, C  aglar\\nGulc ehre, Dzmitry Bahdanau, Fethi Bougares,', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 8}),\n",
       " Document(page_content='Holger Schwenk, and Yoshua Bengio. Learn-\\ning phrase representations using rnn en-\\ncoderdecoder for statistical machine transla-\\ntion. In EMNLP , 2014b.\\nJ. Chung, C  aglar G ulc ehre, Kyunghyun Cho, and\\nYoshua Bengio. Empirical evaluation of gated\\nrecurrent neural networks on sequence model-\\ning.ArXiv , abs/1412.3555, 2014.\\nXavier Glorot and Yoshua Bengio. Understanding\\nthe difculty of training deep feedforward neu-\\nral networks. In AISTATS , 2010.\\nS. Hochreiter. The vanishing gradient problem\\nduring learning recurrent neural nets and prob-\\nlem solutions. Int. J. Uncertain. Fuzziness\\nKnowl. Based Syst. , 6:107116, 1998.\\nS. Hochreiter and J. Schmidhuber. Long short-\\nterm memory. Neural Computation , 9:1735\\n1780, 1997.\\nSebastien Jean, Kyunghyun Cho, R. Memisevic,\\nand Yoshua Bengio. On using very large tar-\\nget vocabulary for neural machine translation.\\nArXiv , abs/1412.2007, 2015.\\nMarcin Junczys-Dowmunt, Tomasz Dwojak, and\\nHieu Hoang. Is neural machine translation\\nready for deployment? a case study on 30 trans-\\nlation directions. 01 2016.\\nPhilipp Koehn. Europarl: A parallel corpus for\\nstatistical machine translation. In MTSUMMIT ,\\n2005.\\nPhilipp Koehn, Franz Josef Och, and Daniel\\nMarcu. Statistical phrase-based translation.\\nInProceedings of the 2003 Conference of the\\nNorth American Chapter of the Association\\nfor Computational Linguistics on Human Lan-\\nguage Technology - Volume 1 , NAACL 03,\\npage 4854, USA, 2003. Association for Com-\\nputational Linguistics. doi: 10.3115/1073445.\\n1073462. URL https://doi.org/10.\\n3115/1073445.1073462 .\\nThang Luong, Hieu Pham, and Christopher D.\\nManning. Effective approaches to attention-\\nbased neural machine translation. In EMNLP ,\\n2015.\\nKishore Papineni, S. Roukos, T. Ward, and Wei-\\nJing Zhu. Bleu: a method for automatic evalua-\\ntion of machine translation. In ACL, 2002.\\nR. Rana. Gated recurrent unit (gru) for emo-\\ntion classication from noisy speech. ArXiv ,\\nabs/1612.07778, 2016.M. Schuster and K. Paliwal. Bidirectional recur-\\nrent neural networks. IEEE Trans. Signal Pro-\\ncess. , 45:26732681, 1997.\\nXuewen Shi, Heyan Huang, Ping Jian, and Yi-Kun\\nTang. Improving neural machine translation\\nwith sentence alignment learning. Neurocom-\\nputing , 420:1526, 2021. ISSN 0925-2312. doi:\\nhttps://doi.org/10.1016/j.neucom.2020.05.104.\\nIlya Sutskever, Oriol Vinyals, and Quoc V . Le.\\nSequence to sequence learning with neural net-\\nworks. In NIPS , 2014.\\nShuangzhi Wu, Dongdong Zhang, Zhirui Zhang,\\nNan Yang, Mu Li, and M. Zhou. Dependency-\\nto-dependency neural machine translation.\\nIEEE/ACM Transactions on Audio, Speech, and\\nLanguage Processing , 26:21322141, 2018.', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 9}),\n",
       " Document(page_content='Source senor presidente , se nor presidente en ejercicio del consejo , se nor presidente de la\\ncomisi on , se noras , me gustar a hacer tres breves comentarios .\\nReference mr president , mr president - in - ofce of the council , mr president of the com-\\nmission , ladies and gentlemen , i would just like to make three brief comments\\n.\\nOur Model president mr president , mr president - in - ofce of the council , mr president of\\nthe commission , ladies and gentlemen , i would like to make three brief comments\\nbrief comments .\\nGoogle Translate Mr. Chairman, Mr. Chairman-in-Ofce of the Council, Mr. Chairman of the Com-\\nmittee, ladies and gentlemen, I would like to make three brief comments.\\nSource como los estados miembros , la comisi on procura promover el estado de derecho ,\\nsin el cual los derechos humanos no obtendr an reconocimiento en ning un territorio\\n.\\nReference the commission is involved , as are member states , in the promotion of the rule of\\nlaw , without which human rights can not operate in any territory .\\nOur Model that as the member states , the commission intends to promote the rule of law ,\\nwithout human rights will not not be any recognition in any territory in any territory\\n.\\nGoogle Translate Like the member states, the commission seeks to promote the rule of law, without\\nwhich human rights will not be recognized in any territory.\\nSource por escrito . - he votado a favor del informe de la se nora fraga , que permite a\\ngroenlandia exportar productos pesqueros a la ue a pesar de no ser miembro .\\nReference in writing . - i voted in favour of ms fraga s report , which allows greenland to\\nexport shery products to the eu despite not being a member .\\nOur Model in writing . - i voted in favour of mrs fraga est evez s report , which allows greenland\\nexport export to export to the eu despite despite not being member .\\nGoogle Translate written . - i voted in favor of the report by mrs fraga, which allows greenland to\\nexport shery products to the eu despite not being a member.\\nSource ( pl ) se nor presidente , me gustar a una vez m as manifestar mi satisfacci on por la\\nimportancia que la comunidad conere a la necesidad de innovaci on en europa .\\nReference ( pl ) mr president , i would like once again to express my pleasure at the importance\\nthat the community attaches to the need for innovation in europe .\\nOur Model that ( pl ) mr president , i would once again like to express my satisfaction satis-\\nfaction that the community attaches to the community to the need for innovation in\\neurope .\\nGoogle Translate (pl) mr president, i would like once again to express my satisfaction with the impor-\\ntance that the community attaches to the need for innovation in europe.\\nSource son los estados miembros de la zona del euro los que no han cumplido , en especial\\nla rep ublica federal de alemania que se niega a mantener su promesa .\\nReference it is the member states of the euro area that have not delivered - and particularly the\\nfederal republic of germany , which is refusing to keep its promise .\\nOur Model that it is the member states of the euro area which have not complied honour ,\\nparticularly the federal republic of germany that refuses to keep their promise to\\nsustain their promise .\\nGoogle Translate it is the eurozone member states that have not delivered, especially the federal re-\\npublic of germany which refuses to keep its promise.\\nTable 4: Source and Reference form the test data, with translated sentence from our model along with\\nGoogle translation (as of 16 August 2021)\\nView publication stats', metadata={'source': 'C:/Users/Admin/Documents/iNeuron/Day 3 Intro to LangChain/MachineTranslationwithAttention.pdf', 'page': 10})]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0addf9-62fe-41ff-8534-d70a0550dc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4367b7-8c67-49b6-86ad-7be4f4c27de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "93be6d81-8f59-447e-8e7d-602d60b4e1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000002E07F89C100>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000002E07F8A1EE0>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2e5e88a5-9835-4d52-a773-6edcdc1fb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key = mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "bf7d353c-6187-42f5-b166-fb306006edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "3b30822b-b831-4021-8426-8ba18ed29a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client, prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e5a3e037-99f2-46db-820c-732d941a39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"CupCrafters\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"coffee cup\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "964da298-7b66-4c59-abf0-1be26bde5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "e63dce0f-c7f0-4903-998d-9f68d800baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SkyTech Drones'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"drones\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "9bb98d2c-939a-4a2e-932a-c9d691263021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "129469b5-6a6c-4cb9-bb8d-0161827e5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NoneType means we are not storing aything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774336a-c92d-4c54-b711-d409f136ab8e",
   "metadata": {},
   "source": [
    "#ConversationBifferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5cfa1-851f-4ae4-87b3-ce0e655bcefb",
   "metadata": {},
   "source": [
    "We can attach memoery to all previous conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "3898bd82-545e-4d73-a2d8-58136d5cd226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a684bcf7-2a59-49cb-8856-ea642ac113a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "f5dc9a44-1ca4-4867-829e-2b68bd1b0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "6386e191-4d86-41d6-a911-735fcf9c8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client, prompt=prompt_template_name, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "1b91362f-5d8b-4632-9296-01406ffa9a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Vineyard Visions\"'"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "aedd4364-2ddd-407a-9567-2ae0ea06a3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. CaptureTech\\n2. ShutterWorks\\n3. LensCrafters\\n4. FocalVision\\n5. SnapTech\\n6. FocusWorks\\n7. PixelPro\\n8. ShotMakers\\n9. ImageCrafters\\n10. VisualVantage'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "bcfb5663-4485-4329-90d7-9e07bb9d92db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"RoadCraft Motors\"'"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "8448c3cd-5c4e-4f75-b430-3b63934d866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Wine'), AIMessage(content='\\n\\n\"Vineyard Visions\"'), HumanMessage(content='Camera'), AIMessage(content='\\n1. CaptureTech\\n2. ShutterWorks\\n3. LensCrafters\\n4. FocalVision\\n5. SnapTech\\n6. FocusWorks\\n7. PixelPro\\n8. ShotMakers\\n9. ImageCrafters\\n10. VisualVantage'), HumanMessage(content='Cars'), AIMessage(content='\\n\\n\"RoadCraft Motors\"')]))"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1069fd67-261b-48a3-8681-1e85f49dfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Wine\n",
      "AI: \n",
      "\n",
      "\"Vineyard Visions\"\n",
      "Human: Camera\n",
      "AI: \n",
      "1. CaptureTech\n",
      "2. ShutterWorks\n",
      "3. LensCrafters\n",
      "4. FocalVision\n",
      "5. SnapTech\n",
      "6. FocusWorks\n",
      "7. PixelPro\n",
      "8. ShotMakers\n",
      "9. ImageCrafters\n",
      "10. VisualVantage\n",
      "Human: Cars\n",
      "AI: \n",
      "\n",
      "\"RoadCraft Motors\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534c9c9-e95a-4645-a84d-fc9712e924c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "511da525-71b2-4175-a8a3-1e030637aa40",
   "metadata": {},
   "source": [
    "ConverstaionChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f3d36-72df-4529-922a-143a979c7f93",
   "metadata": {},
   "source": [
    "Converstaion buffer memory goes growing endlessly \n",
    "\n",
    "Lets remember last 5 Conversation Chain\n",
    "\n",
    "Lets remember last 10 Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "fc5e08e6-07c1-4b0a-8be2-de346105be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f021174-e8db-4834-85bb-fe21dc4a7e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "0817c211-e1b7-4c83-8b90-389b7899f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = ConversationChain(llm=client, memory=ConversationBufferMemory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "b4b99caa-6042-4789-8854-cd5d5eae0d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "a4a40f44-ec10-4ada-9cb2-c26ec9216935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "0d1175f3-137d-4a06-9ba7-d874a04e099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first cricket World Cup was held in 1975 and was won by the West Indies team.'"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first cricket worldcup ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "bea26aeb-9dbd-4977-b6d4-7e479dacae78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Of course, 5+5 is equal to 10. Did you know that 10 is the sum of the first four consecutive numbers (1+2+3+4) and is also known as the triangular number? It is also the atomic number of neon and the number of commandments in the Ten Commandments.'"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"can you tell me how much is 5+5 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "adcf433a-5fdb-423f-9fb0-076582bf06cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the West Indies team in the first cricket World Cup was Clive Lloyd. He was known for his strong leadership and aggressive batting style, leading the team to victory in both the 1975 and 1979 World Cups. Fun fact: he is the only captain to have won the World Cup twice.'"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answers the question as it stores the previous conversation\n",
    "convo.run(\"who was the captain of the winning team ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "a7492e0a-e9d2-46fb-8557-d4d78f56ca5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure, subtracting 3 from 10 would give us a result of 7. Did you know that 7 is a prime number and the only one in the decimal system? It is also the number of days in a week and the number of colors in a rainbow.'"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"can you subtract 3 from the total and tell me the result ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82e9a8-9d63-4538-b1f0-4f6134e511d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ab1dba8c-a2c1-480c-95af-f201e006eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "b2bed361-b91a-4552-8a9a-908411dd09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "6c3f137d-7038-4c01-a173-dffc376633d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k is hyperparameter for how many previous chats model needs to archive\n",
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "be266385-1840-4cd4-b3f4-d6f16912f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = ConversationChain(llm=client, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "cd2ccdfa-72d7-41ab-8ab4-20477c6c99ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was held in 1975 and was won by the West Indies team. They defeated Australia by 17 runs in the final match. The tournament was held in England and was organized by the International Cricket Council.'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first cricket worldcup ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b7f3fe66-70b7-4f70-95d5-2fbfdc1ef2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The answer is 10.'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"can you tell me how much is 5+5 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "6303b64d-0419-471b-a56b-0d51e7e6742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I do not have enough context to answer that question. Can you provide me with more details?'"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only remembers only last 1 memory for k =2 will give correct answer\n",
    "convo.run(\"who was the captain of the winning team ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ef219-44e1-4b62-b5d3-01361e81bf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83735b-6a00-46d0-bf3f-3a3c625958bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
